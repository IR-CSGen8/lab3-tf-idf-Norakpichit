{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720e4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math #important library , calculate log\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd950e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample collection of documents\n",
    "documents = [\n",
    "    \"Scientists have discovered a new species of marine life in the deep ocean.\",\n",
    "    \"NASA's Mars rover is searching for signs of ancient life on the Red Planet.\",\n",
    "    \"The stock market experienced a significant drop in trading today.\",\n",
    "    \"Astronomers have identified a distant galaxy with unusual star formations.\",\n",
    "    \"The government announced new measures to combat climate change.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ea50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for lemmatization (a simple example, not comprehensive)\n",
    "lemmatization_dict = {\n",
    "    \"species\": \"specie\",\n",
    "    \"species\": \"species\",\n",
    "    \"oceans\": \"ocean\",\n",
    "    \"ocean's\": \"ocean\",\n",
    "    \"rover\": \"rover\",\n",
    "    \"discovered\":\"discover\",\n",
    "    \"experienced\":\"experience\",\n",
    "    \"rovers\": \"rover\",\n",
    "    \"trading\": \"trade\",\n",
    "    \"identified\": \"identify\",\n",
    "    \"identifies\": \"identify\",\n",
    "    \"formations\": \"formation\",\n",
    "    \"governments\": \"government\",\n",
    "    \"measures\": \"measure\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f1f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [lemmatization_dict.get(term, term) for term in lemmatization_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed247b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize documents into words (terms), remove punctuation, and lemmatize\n",
    "def preprocess_text(document):\n",
    "    terms = document.lower().split()\n",
    "    terms = [term.strip(string.punctuation) for term in terms]\n",
    "    terms = [lemmatization_dict.get(term, term) for term in terms]\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34cee75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of unique terms (vocabulary)\n",
    "vocabulary = set()\n",
    "# you code here ...\n",
    "for document in documents:\n",
    "    vocabulary.update(preprocess_text(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc32da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'searching': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'is': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'in': [0.013513513513513514, 0, 0.015384615384615385, 0, 0],\n",
       " 'announced': [0, 0, 0, 0, 0.015873015873015872],\n",
       " 'scientists': [0.013513513513513514, 0, 0, 0, 0],\n",
       " 'of': [0.013513513513513514, 0.013333333333333334, 0, 0, 0],\n",
       " 'drop': [0, 0, 0.015384615384615385, 0, 0],\n",
       " 'stock': [0, 0, 0.015384615384615385, 0, 0],\n",
       " 'trade': [0, 0, 0.015384615384615385, 0, 0],\n",
       " 'identify': [0, 0, 0, 0.013513513513513514, 0],\n",
       " 'with': [0, 0, 0, 0.013513513513513514, 0],\n",
       " 'climate': [0, 0, 0, 0, 0.015873015873015872],\n",
       " 'ocean': [0.013513513513513514, 0, 0, 0, 0],\n",
       " 'have': [0.013513513513513514, 0, 0, 0.013513513513513514, 0],\n",
       " 'the': [0.013513513513513514,\n",
       "  0.013333333333333334,\n",
       "  0.015384615384615385,\n",
       "  0,\n",
       "  0.015873015873015872],\n",
       " 'formation': [0, 0, 0, 0.013513513513513514, 0],\n",
       " 'discover': [0.013513513513513514, 0, 0, 0, 0],\n",
       " 'deep': [0.013513513513513514, 0, 0, 0, 0],\n",
       " 'life': [0.013513513513513514, 0.013333333333333334, 0, 0, 0],\n",
       " 'government': [0, 0, 0, 0, 0.015873015873015872],\n",
       " \"nasa's\": [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'on': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'measure': [0, 0, 0, 0, 0.015873015873015872],\n",
       " 'species': [0.013513513513513514, 0, 0, 0, 0],\n",
       " 'a': [0.013513513513513514, 0, 0.015384615384615385, 0.013513513513513514, 0],\n",
       " 'to': [0, 0, 0, 0, 0.015873015873015872],\n",
       " 'unusual': [0, 0, 0, 0.013513513513513514, 0],\n",
       " 'market': [0, 0, 0.015384615384615385, 0, 0],\n",
       " 'rover': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'galaxy': [0, 0, 0, 0.013513513513513514, 0],\n",
       " 'change': [0, 0, 0, 0, 0.015873015873015872],\n",
       " 'distant': [0, 0, 0, 0.013513513513513514, 0],\n",
       " 'mars': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'astronomers': [0, 0, 0, 0.013513513513513514, 0],\n",
       " 'significant': [0, 0, 0.015384615384615385, 0, 0],\n",
       " 'experience': [0, 0, 0.015384615384615385, 0, 0],\n",
       " 'new': [0.013513513513513514, 0, 0, 0, 0.015873015873015872],\n",
       " 'for': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'star': [0, 0, 0, 0.013513513513513514, 0],\n",
       " 'combat': [0, 0, 0, 0, 0.015873015873015872],\n",
       " 'marine': [0.013513513513513514, 0, 0, 0, 0],\n",
       " 'planet': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'red': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'ancient': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'signs': [0, 0.013333333333333334, 0, 0, 0],\n",
       " 'today': [0, 0, 0.015384615384615385, 0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store the term frequency (TF) for each term in each document\n",
    "tf_values = {term: [0] * len(documents) for term in vocabulary}\n",
    "# Calculate Term Frequency (TF)\n",
    "for i, document in enumerate(documents):\n",
    "   for term in preprocess_text(document):\n",
    "       tf_values[term][i] = preprocess_text(document).count(term) / len(document)\n",
    "\n",
    "tf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d91fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'searching': 0.6989700043360187,\n",
       " 'is': 0.6989700043360187,\n",
       " 'in': 0.3979400086720376,\n",
       " 'announced': 0.6989700043360187,\n",
       " 'scientists': 0.6989700043360187,\n",
       " 'of': 0.3979400086720376,\n",
       " 'drop': 0.6989700043360187,\n",
       " 'stock': 0.6989700043360187,\n",
       " 'trade': 0.6989700043360187,\n",
       " 'identify': 0.6989700043360187,\n",
       " 'with': 0.6989700043360187,\n",
       " 'climate': 0.6989700043360187,\n",
       " 'ocean': 0.6989700043360187,\n",
       " 'have': 0.3979400086720376,\n",
       " 'the': 0.0969100130080564,\n",
       " 'formation': 0.6989700043360187,\n",
       " 'discover': 0.6989700043360187,\n",
       " 'deep': 0.6989700043360187,\n",
       " 'life': 0.3979400086720376,\n",
       " 'government': 0.6989700043360187,\n",
       " \"nasa's\": 0.6989700043360187,\n",
       " 'on': 0.6989700043360187,\n",
       " 'measure': 0.6989700043360187,\n",
       " 'species': 0.6989700043360187,\n",
       " 'a': 0.22184874961635637,\n",
       " 'to': 0.6989700043360187,\n",
       " 'unusual': 0.6989700043360187,\n",
       " 'market': 0.6989700043360187,\n",
       " 'rover': 0.6989700043360187,\n",
       " 'galaxy': 0.6989700043360187,\n",
       " 'change': 0.6989700043360187,\n",
       " 'distant': 0.6989700043360187,\n",
       " 'mars': 0.6989700043360187,\n",
       " 'astronomers': 0.6989700043360187,\n",
       " 'significant': 0.6989700043360187,\n",
       " 'experience': 0.6989700043360187,\n",
       " 'new': 0.3979400086720376,\n",
       " 'for': 0.6989700043360187,\n",
       " 'star': 0.6989700043360187,\n",
       " 'combat': 0.6989700043360187,\n",
       " 'marine': 0.6989700043360187,\n",
       " 'planet': 0.6989700043360187,\n",
       " 'red': 0.6989700043360187,\n",
       " 'ancient': 0.6989700043360187,\n",
       " 'signs': 0.6989700043360187,\n",
       " 'today': 0.6989700043360187}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate DF\n",
    "total_documents = len(documents)\n",
    "df_values = {term: 0 for term in vocabulary}\n",
    "for document in documents:\n",
    "    for term in vocabulary:\n",
    "        if term in preprocess_text(document):\n",
    "            df_values[term] += 1\n",
    "# Calculate Inverse Document Frequency (IDF)\n",
    "idf_values = {term: 0 for term in vocabulary}\n",
    "\n",
    "for term in vocabulary:\n",
    "    idf_values[term] = math.log((total_documents / df_values[term]), 10)\n",
    "\n",
    "idf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be824663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF values\n",
    "tfidf_values = []\n",
    "for i, document in enumerate(documents):\n",
    "    terms = preprocess_text(document)\n",
    "    tfidf_document = []\n",
    "    for term in vocabulary:\n",
    "        tf = tf_values[term][i]\n",
    "        idf = idf_values[term]\n",
    "        tfidf = tf * idf\n",
    "        tfidf_document.append(tfidf)\n",
    "    tfidf_values.append(tfidf_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99f53d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF:\n",
      "   searching       is        in  announced  scientists        of      drop  \\\n",
      "0    0.00000  0.00000  0.005378   0.000000    0.009446  0.005378  0.000000   \n",
      "1    0.00932  0.00932  0.000000   0.000000    0.000000  0.005306  0.000000   \n",
      "2    0.00000  0.00000  0.006122   0.000000    0.000000  0.000000  0.010753   \n",
      "3    0.00000  0.00000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "4    0.00000  0.00000  0.000000   0.011095    0.000000  0.000000  0.000000   \n",
      "\n",
      "      stock     trade  identify  ...       new      for      star    combat  \\\n",
      "0  0.000000  0.000000  0.000000  ...  0.005378  0.00000  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  ...  0.000000  0.00932  0.000000  0.000000   \n",
      "2  0.010753  0.010753  0.000000  ...  0.000000  0.00000  0.000000  0.000000   \n",
      "3  0.000000  0.000000  0.009446  ...  0.000000  0.00000  0.009446  0.000000   \n",
      "4  0.000000  0.000000  0.000000  ...  0.006317  0.00000  0.000000  0.011095   \n",
      "\n",
      "     marine   planet      red  ancient    signs     today  \n",
      "0  0.009446  0.00000  0.00000  0.00000  0.00000  0.000000  \n",
      "1  0.000000  0.00932  0.00932  0.00932  0.00932  0.000000  \n",
      "2  0.000000  0.00000  0.00000  0.00000  0.00000  0.010753  \n",
      "3  0.000000  0.00000  0.00000  0.00000  0.00000  0.000000  \n",
      "4  0.000000  0.00000  0.00000  0.00000  0.00000  0.000000  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert TF-IDF values to a DataFrame\n",
    "df_tfidf = pd.DataFrame(tfidf_values, columns=list(vocabulary))\n",
    "\n",
    "# Display TF-IDF results\n",
    "print(\"TF-IDF:\")\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9fcbe8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF-IDF results to a CSV file (optional)\n",
    "df_tfidf.to_csv(\"tfidf_custom_preprocessed_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36077c4e",
   "metadata": {},
   "source": [
    "# Using Libraries for Lemmatization and Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0495e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\norak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if your machine doesn't have these libraries, you need to install them\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# download the punkt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "69087c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\norak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\norak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\norak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize NLTK's lemmatizer and download stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "# Initialize NLTK's lemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Tokenize documents into words (terms), remove punctuation, lemmatize, and remove stopwords\n",
    "def preprocess_text(document):\n",
    "    terms = nltk.word_tokenize(document)\n",
    "    terms = [term.strip(string.punctuation) for term in terms]\n",
    "    terms = [ps.stem(term) for term in terms]\n",
    "    terms = [term.lower() for term in terms if term not in stopwords.words('english')]\n",
    "    return ' '.join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0c050db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scientist discov new speci marin life deep ocean ', 'nasa mar rover search sign ancient life red planet ', 'stock market experienc signific drop trade today ', 'astronom identifi distant galaxi unusu star format ', 'govern announc new measur combat climat chang ']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text in the documents\n",
    "preprocessed_documents = [preprocess_text(document) for document in documents]\n",
    "print(preprocessed_documents)\n",
    "# Create a TfidfVectorizer instance\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2ded965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the preprocessed documents to compute TF-IDF values CADT@0zJanZ!\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_documents)\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d2e4c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF:\n",
      "    ancient   announc  astronom     chang    climat    combat     deep  \\\n",
      "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.37007   \n",
      "1  0.339992  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
      "3  0.000000  0.000000  0.377964  0.000000  0.000000  0.000000  0.00000   \n",
      "4  0.000000  0.387757  0.000000  0.387757  0.387757  0.387757  0.00000   \n",
      "\n",
      "    discov   distant      drop  ...  scientist    search      sign  signific  \\\n",
      "0  0.37007  0.000000  0.000000  ...    0.37007  0.000000  0.000000  0.000000   \n",
      "1  0.00000  0.000000  0.000000  ...    0.00000  0.339992  0.339992  0.000000   \n",
      "2  0.00000  0.000000  0.377964  ...    0.00000  0.000000  0.000000  0.377964   \n",
      "3  0.00000  0.377964  0.000000  ...    0.00000  0.000000  0.000000  0.000000   \n",
      "4  0.00000  0.000000  0.000000  ...    0.00000  0.000000  0.000000  0.000000   \n",
      "\n",
      "     speci      star     stock     today     trade     unusu  \n",
      "0  0.37007  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2  0.00000  0.000000  0.377964  0.377964  0.377964  0.000000  \n",
      "3  0.00000  0.377964  0.000000  0.000000  0.000000  0.377964  \n",
      "4  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display TF-IDF results\n",
    "print(\"TF-IDF:\")\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7fa70aeb-2365-4762-a99f-a62a9c075007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Lab 3 - tf-idf.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "669bece2-78fd-4e1a-a9d0-e5d5bd2aca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 49d015a] Submitted\n",
      " 2 files changed, 109 insertions(+), 68 deletions(-)\n",
      " create mode 100644 tfidf_custom_preprocessed_news.csv\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Submitted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "707249a4-d128-4e75-b866-e8e5e61bef74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/IR-CSGen8/lab3-tf-idf-Norakpichit.git\n",
      "   3bdc70a..49d015a  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4058b8e0-4b77-4f2f-ab74-1d1324d1bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tfidf_custom_preprocessed_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1aed13ec-8485-443c-8e0b-b29794f0d6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>government</th>\n",
       "      <th>drop</th>\n",
       "      <th>scientists</th>\n",
       "      <th>trade</th>\n",
       "      <th>to</th>\n",
       "      <th>in</th>\n",
       "      <th>signs</th>\n",
       "      <th>identify</th>\n",
       "      <th>is</th>\n",
       "      <th>market</th>\n",
       "      <th>...</th>\n",
       "      <th>deep</th>\n",
       "      <th>ocean</th>\n",
       "      <th>experience</th>\n",
       "      <th>ancient</th>\n",
       "      <th>of</th>\n",
       "      <th>with</th>\n",
       "      <th>the</th>\n",
       "      <th>rover</th>\n",
       "      <th>species</th>\n",
       "      <th>combat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09691</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09691</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09691</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09691</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   government     drop  scientists    trade       to       in    signs  \\\n",
       "0     0.00000  0.00000     0.69897  0.00000  0.00000  0.39794  0.00000   \n",
       "1     0.00000  0.00000     0.00000  0.00000  0.00000  0.00000  0.69897   \n",
       "2     0.00000  0.69897     0.00000  0.69897  0.00000  0.39794  0.00000   \n",
       "3     0.00000  0.00000     0.00000  0.00000  0.00000  0.00000  0.00000   \n",
       "4     0.69897  0.00000     0.00000  0.00000  0.69897  0.00000  0.00000   \n",
       "\n",
       "   identify       is   market  ...     deep    ocean  experience  ancient  \\\n",
       "0   0.00000  0.00000  0.00000  ...  0.69897  0.69897     0.00000  0.00000   \n",
       "1   0.00000  0.69897  0.00000  ...  0.00000  0.00000     0.00000  0.69897   \n",
       "2   0.00000  0.00000  0.69897  ...  0.00000  0.00000     0.69897  0.00000   \n",
       "3   0.69897  0.00000  0.00000  ...  0.00000  0.00000     0.00000  0.00000   \n",
       "4   0.00000  0.00000  0.00000  ...  0.00000  0.00000     0.00000  0.00000   \n",
       "\n",
       "        of     with      the    rover  species   combat  \n",
       "0  0.39794  0.00000  0.09691  0.00000  0.69897  0.00000  \n",
       "1  0.39794  0.00000  0.09691  0.69897  0.00000  0.00000  \n",
       "2  0.00000  0.00000  0.09691  0.00000  0.00000  0.00000  \n",
       "3  0.00000  0.69897  0.00000  0.00000  0.00000  0.00000  \n",
       "4  0.00000  0.00000  0.09691  0.00000  0.00000  0.69897  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fbd2db-aab7-4bc8-9a08-89e640dd2071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
